{"name":"Neural","tagline":"Neural Network playground for Node and the browser","body":"<a name=\"module_neural\"></a>\r\n## neural\r\nA neural network toolkit for Node.js and the browser.\r\n\r\n\r\n* [neural](#module_neural)\r\n    * [~Neuron](#module_neural..Neuron)\r\n        * [new Neuron(params)](#new_module_neural..Neuron_new)\r\n        * [.setInputs(newInputs)](#module_neural..Neuron+setInputs)\r\n        * [.getInputs()](#module_neural..Neuron+getInputs) ⇒ <code>Array</code>\r\n        * [.getInputCount()](#module_neural..Neuron+getInputCount) ⇒ <code>number</code>\r\n        * [.setWeights(newWeights)](#module_neural..Neuron+setWeights)\r\n        * [.getWeights()](#module_neural..Neuron+getWeights) ⇒ <code>Array</code>\r\n        * [.getId()](#module_neural..Neuron+getId) ⇒ <code>number</code>\r\n        * [.getTransfer()](#module_neural..Neuron+getTransfer) ⇒ <code>fn</code>\r\n        * [.setTransfer(The)](#module_neural..Neuron+setTransfer)\r\n        * [.getActivation()](#module_neural..Neuron+getActivation) ⇒ <code>number</code>\r\n        * [.getInputSum()](#module_neural..Neuron+getInputSum) ⇒ <code>number</code>\r\n        * [.getDelta()](#module_neural..Neuron+getDelta) ⇒ <code>number</code>\r\n        * [.isOutput()](#module_neural..Neuron+isOutput) ⇒ <code>boolean</code>\r\n        * [.setExpected(Expected)](#module_neural..Neuron+setExpected)\r\n        * [.addInput(The)](#module_neural..Neuron+addInput)\r\n        * [.calc()](#module_neural..Neuron+calc) ⇒ <code>number</code>\r\n        * [.error()](#module_neural..Neuron+error) ⇒ <code>number</code>\r\n        * [.invalidate()](#module_neural..Neuron+invalidate)\r\n        * [.calcDelta()](#module_neural..Neuron+calcDelta) ⇒ <code>number</code>\r\n        * [.getOutputWeightPartials()](#module_neural..Neuron+getOutputWeightPartials) ⇒ <code>Array</code>\r\n        * [.getInputWeightPartials()](#module_neural..Neuron+getInputWeightPartials) ⇒ <code>Array</code>\r\n        * [.randomizeWeights([max], [min])](#module_neural..Neuron+randomizeWeights)\r\n    * [~Layer](#module_neural..Layer)\r\n        * [new Layer(params)](#new_module_neural..Layer_new)\r\n        * [.isOutput()](#module_neural..Layer+isOutput) ⇒ <code>boolean</code>\r\n        * [.setStatus(statuses)](#module_neural..Layer+setStatus)\r\n        * [.plug(outputLayer)](#module_neural..Layer+plug) ⇒ <code>Layer</code>\r\n        * [.getNeurons()](#module_neural..Layer+getNeurons) ⇒ <code>Array</code>\r\n        * [.setInputs(inputs, isInputLayer)](#module_neural..Layer+setInputs)\r\n        * [.setExpected(An)](#module_neural..Layer+setExpected)\r\n        * [.setTransfer(fn)](#module_neural..Layer+setTransfer)\r\n        * [.calc()](#module_neural..Layer+calc) ⇒ <code>Array</code>\r\n        * [.invalidate()](#module_neural..Layer+invalidate)\r\n        * [.calcDeltas()](#module_neural..Layer+calcDeltas) ⇒ <code>Array</code>\r\n        * [.getWeights()](#module_neural..Layer+getWeights) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.setWeights(weights)](#module_neural..Layer+setWeights)\r\n        * [.getActivations()](#module_neural..Layer+getActivations) ⇒ <code>Array</code>\r\n        * [.getInputSums()](#module_neural..Layer+getInputSums) ⇒ <code>Array</code>\r\n        * [.getIds()](#module_neural..Layer+getIds) ⇒ <code>Array</code>\r\n        * [.getOutputWeightPartials()](#module_neural..Layer+getOutputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.getInputWeightPartials()](#module_neural..Layer+getInputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.randomizeWeights(e)](#module_neural..Layer+randomizeWeights)\r\n    * [~Network](#module_neural..Network)\r\n        * [new Network(params)](#new_module_neural..Network_new)\r\n        * [.layerCount()](#module_neural..Network+layerCount) ⇒ <code>number</code>\r\n        * [.getLayers()](#module_neural..Network+getLayers) ⇒ <code>Array</code>\r\n        * [.inputLayer()](#module_neural..Network+inputLayer) ⇒ <code>Layer</code>\r\n        * [.outputLayer()](#module_neural..Network+outputLayer) ⇒ <code>Layer</code>\r\n        * [.setInputs(inputs)](#module_neural..Network+setInputs)\r\n        * [.setExpected(outputs)](#module_neural..Network+setExpected)\r\n        * [.calc()](#module_neural..Network+calc) ⇒ <code>Array</code>\r\n        * [.getActivations()](#module_neural..Network+getActivations) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.getInputSums()](#module_neural..Network+getInputSums) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.invalidate()](#module_neural..Network+invalidate)\r\n        * [.randomizeWeights(e)](#module_neural..Network+randomizeWeights)\r\n        * [.forwardPropagate(trial)](#module_neural..Network+forwardPropagate) ⇒ <code>Array.&lt;number&gt;</code>\r\n        * [.sumSqError()](#module_neural..Network+sumSqError) ⇒ <code>number</code>\r\n        * [.backPropagate()](#module_neural..Network+backPropagate) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.getIds()](#module_neural..Network+getIds) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n        * [.getOutputWeightPartials()](#module_neural..Network+getOutputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n        * [.getInputWeightPartials()](#module_neural..Network+getInputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n        * [.getWeights()](#module_neural..Network+getWeights) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n        * [.setWeights(The)](#module_neural..Network+setWeights)\r\n    * [~TrainingData](#module_neural..TrainingData)\r\n        * [new TrainingData(data)](#new_module_neural..TrainingData_new)\r\n        * [.dataGenerator()](#module_neural..TrainingData+dataGenerator) ⇒ <code>generator</code>\r\n        * [.dataLength()](#module_neural..TrainingData+dataLength) ⇒ <code>number</code>\r\n    * [~transferFunctions](#module_neural..transferFunctions) : <code>object</code>\r\n    * [~addTransferFunction(key, fn, deriv)](#module_neural..addTransferFunction)\r\n    * [~one-to-one](#module_neural..one-to-one) ⇒ <code>number</code>\r\n\r\n<a name=\"module_neural..Neuron\"></a>\r\n### neural~Neuron\r\n**Kind**: inner class of <code>[neural](#module_neural)</code>  \r\n\r\n* [~Neuron](#module_neural..Neuron)\r\n    * [new Neuron(params)](#new_module_neural..Neuron_new)\r\n    * [.setInputs(newInputs)](#module_neural..Neuron+setInputs)\r\n    * [.getInputs()](#module_neural..Neuron+getInputs) ⇒ <code>Array</code>\r\n    * [.getInputCount()](#module_neural..Neuron+getInputCount) ⇒ <code>number</code>\r\n    * [.setWeights(newWeights)](#module_neural..Neuron+setWeights)\r\n    * [.getWeights()](#module_neural..Neuron+getWeights) ⇒ <code>Array</code>\r\n    * [.getId()](#module_neural..Neuron+getId) ⇒ <code>number</code>\r\n    * [.getTransfer()](#module_neural..Neuron+getTransfer) ⇒ <code>fn</code>\r\n    * [.setTransfer(The)](#module_neural..Neuron+setTransfer)\r\n    * [.getActivation()](#module_neural..Neuron+getActivation) ⇒ <code>number</code>\r\n    * [.getInputSum()](#module_neural..Neuron+getInputSum) ⇒ <code>number</code>\r\n    * [.getDelta()](#module_neural..Neuron+getDelta) ⇒ <code>number</code>\r\n    * [.isOutput()](#module_neural..Neuron+isOutput) ⇒ <code>boolean</code>\r\n    * [.setExpected(Expected)](#module_neural..Neuron+setExpected)\r\n    * [.addInput(The)](#module_neural..Neuron+addInput)\r\n    * [.calc()](#module_neural..Neuron+calc) ⇒ <code>number</code>\r\n    * [.error()](#module_neural..Neuron+error) ⇒ <code>number</code>\r\n    * [.invalidate()](#module_neural..Neuron+invalidate)\r\n    * [.calcDelta()](#module_neural..Neuron+calcDelta) ⇒ <code>number</code>\r\n    * [.getOutputWeightPartials()](#module_neural..Neuron+getOutputWeightPartials) ⇒ <code>Array</code>\r\n    * [.getInputWeightPartials()](#module_neural..Neuron+getInputWeightPartials) ⇒ <code>Array</code>\r\n    * [.randomizeWeights([max], [min])](#module_neural..Neuron+randomizeWeights)\r\n\r\n<a name=\"new_module_neural..Neuron_new\"></a>\r\n#### new Neuron(params)\r\nCreates a new Neuron\r\n\r\n\r\n| Param | Type | Default | Description |\r\n| --- | --- | --- | --- |\r\n| params | <code>Object</code> |  |  |\r\n| [params.transfer] | <code>function</code> | <code>&#x27;logSigmoid&#x27;</code> | The neuron's transfer function. |\r\n| [params.inputs] | <code>Array.&lt;number&gt;</code> |  | An array of inputs to the neuron, which can be numbers, functions returning a number or Neurons |\r\n| [params.weights] | <code>Array.&lt;number&gt;</code> |  | The input weights with which to initialise the Neuron.  Defaults to zeros. |\r\n\r\n<a name=\"module_neural..Neuron+setInputs\"></a>\r\n#### neuron.setInputs(newInputs)\r\nResets the inputs to a neuron.  Any existing inputs are removed.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| newInputs | <code>Array.&lt;(number\\|function()\\|Neuron)&gt;</code> | Array of inputs to the Neuron, which can be numbers, functions returning a number or Neurons. |\r\n\r\n<a name=\"module_neural..Neuron+getInputs\"></a>\r\n#### neuron.getInputs() ⇒ <code>Array</code>\r\nReturns the Neurons inputs.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>Array</code> - The Neurons inputs, which could be numbers, functions returning a number or Neurons.  \r\n<a name=\"module_neural..Neuron+getInputCount\"></a>\r\n#### neuron.getInputCount() ⇒ <code>number</code>\r\nReturns the number of inputs feeding this neuron.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - count of inputs, which could be numbers, functions returning a number of Neurons.  \r\n<a name=\"module_neural..Neuron+setWeights\"></a>\r\n#### neuron.setWeights(newWeights)\r\nUpdates the Neuron's weights.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| newWeights | <code>Array.&lt;number&gt;</code> | An array of numbers, which must be of the same length as the Neuron's array of inputs. |\r\n\r\n<a name=\"module_neural..Neuron+getWeights\"></a>\r\n#### neuron.getWeights() ⇒ <code>Array</code>\r\nReturns the Neuron's weights.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>Array</code> - The neuron's weights (numbers).  \r\n<a name=\"module_neural..Neuron+getId\"></a>\r\n#### neuron.getId() ⇒ <code>number</code>\r\nReturns the Neuron's id.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The Neuron's id, which is unique at the module level.  \r\n<a name=\"module_neural..Neuron+getTransfer\"></a>\r\n#### neuron.getTransfer() ⇒ <code>fn</code>\r\nGet the Neuron's transfer function\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>fn</code> - The transfer function  \r\n<a name=\"module_neural..Neuron+setTransfer\"></a>\r\n#### neuron.setTransfer(The)\r\nSets the Neuron's transfer function\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| The | <code>function</code> | replacement transfer function (see section on transfer functions for details of acceptable formats). |\r\n\r\n<a name=\"module_neural..Neuron+getActivation\"></a>\r\n#### neuron.getActivation() ⇒ <code>number</code>\r\nGets the Neuron's current activation value.  Note that this does NOT recalculate the value if input values or weights have changed.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The most recently-calculated activation value.  \r\n<a name=\"module_neural..Neuron+getInputSum\"></a>\r\n#### neuron.getInputSum() ⇒ <code>number</code>\r\nGets the Neuron's current input sum.  This is the weighted sum of inputs, prior to having been passed through the transfer function. Note that this does NOT recalculate the value if input values or weights have changed.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The most recently-calculated input sum.  \r\n<a name=\"module_neural..Neuron+getDelta\"></a>\r\n#### neuron.getDelta() ⇒ <code>number</code>\r\nGets the Neuron's current delta.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The Neuron's delta.  \r\n<a name=\"module_neural..Neuron+isOutput\"></a>\r\n#### neuron.isOutput() ⇒ <code>boolean</code>\r\nIndicates whether the Neuron is in the output layer of a Network\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n<a name=\"module_neural..Neuron+setExpected\"></a>\r\n#### neuron.setExpected(Expected)\r\nSets the expected activation value (from training data) of the Neuron\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| Expected | <code>number</code> | output value |\r\n\r\n<a name=\"module_neural..Neuron+addInput\"></a>\r\n#### neuron.addInput(The)\r\nPlugs in a new input to the Neuron, which is initialised with a respective weight of 0.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| The | <code>number</code> &#124; <code>function</code> &#124; <code>Neuron</code> | new input. |\r\n\r\n<a name=\"module_neural..Neuron+calc\"></a>\r\n#### neuron.calc() ⇒ <code>number</code>\r\nRecalculates the activation value, recalculating all the input nodes in turn as required.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The recalculated activation value.  \r\n<a name=\"module_neural..Neuron+error\"></a>\r\n#### neuron.error() ⇒ <code>number</code>\r\nThe difference between the most recently calculated activation value and the last expected value to be supplied.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - Difference between activation and expected values.  \r\n<a name=\"module_neural..Neuron+invalidate\"></a>\r\n#### neuron.invalidate()\r\nMarks the Neuron as in need of recalculation by clearing the activation value cache.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n<a name=\"module_neural..Neuron+calcDelta\"></a>\r\n#### neuron.calcDelta() ⇒ <code>number</code>\r\nRecalculates the Neuron's delta.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>number</code> - The new delta.  \r\n<a name=\"module_neural..Neuron+getOutputWeightPartials\"></a>\r\n#### neuron.getOutputWeightPartials() ⇒ <code>Array</code>\r\nReturns the partial derivative of the Neuron's error with respect to its output weights.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>Array</code> - The output weight partials.  \r\n<a name=\"module_neural..Neuron+getInputWeightPartials\"></a>\r\n#### neuron.getInputWeightPartials() ⇒ <code>Array</code>\r\nReturns the partial derivatives of the input Neurons errors with respect to this Neuron's input weights.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n**Returns**: <code>Array</code> - The input weight partials.  \r\n<a name=\"module_neural..Neuron+randomizeWeights\"></a>\r\n#### neuron.randomizeWeights([max], [min])\r\nRandomizes the Neuron's input weights.\r\n\r\n**Kind**: instance method of <code>[Neuron](#module_neural..Neuron)</code>  \r\n\r\n| Param | Type | Default | Description |\r\n| --- | --- | --- | --- |\r\n| [max] | <code>number</code> | <code>0.000001</code> | Maximum possible weight. |\r\n| [min] | <code>number</code> | <code>0</code> | Minimum possible weights. |\r\n\r\n<a name=\"module_neural..Layer\"></a>\r\n### neural~Layer\r\n**Kind**: inner class of <code>[neural](#module_neural)</code>  \r\n\r\n* [~Layer](#module_neural..Layer)\r\n    * [new Layer(params)](#new_module_neural..Layer_new)\r\n    * [.isOutput()](#module_neural..Layer+isOutput) ⇒ <code>boolean</code>\r\n    * [.setStatus(statuses)](#module_neural..Layer+setStatus)\r\n    * [.plug(outputLayer)](#module_neural..Layer+plug) ⇒ <code>Layer</code>\r\n    * [.getNeurons()](#module_neural..Layer+getNeurons) ⇒ <code>Array</code>\r\n    * [.setInputs(inputs, isInputLayer)](#module_neural..Layer+setInputs)\r\n    * [.setExpected(An)](#module_neural..Layer+setExpected)\r\n    * [.setTransfer(fn)](#module_neural..Layer+setTransfer)\r\n    * [.calc()](#module_neural..Layer+calc) ⇒ <code>Array</code>\r\n    * [.invalidate()](#module_neural..Layer+invalidate)\r\n    * [.calcDeltas()](#module_neural..Layer+calcDeltas) ⇒ <code>Array</code>\r\n    * [.getWeights()](#module_neural..Layer+getWeights) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.setWeights(weights)](#module_neural..Layer+setWeights)\r\n    * [.getActivations()](#module_neural..Layer+getActivations) ⇒ <code>Array</code>\r\n    * [.getInputSums()](#module_neural..Layer+getInputSums) ⇒ <code>Array</code>\r\n    * [.getIds()](#module_neural..Layer+getIds) ⇒ <code>Array</code>\r\n    * [.getOutputWeightPartials()](#module_neural..Layer+getOutputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.getInputWeightPartials()](#module_neural..Layer+getInputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.randomizeWeights(e)](#module_neural..Layer+randomizeWeights)\r\n\r\n<a name=\"new_module_neural..Layer_new\"></a>\r\n#### new Layer(params)\r\nCreates a new Network Layer\r\n\r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| params | <code>Object</code> |  |\r\n| [params.neurons] | <code>number</code> &#124; <code>Array.&lt;Neuron&gt;</code> | The Neurons in the layer. If an integer is passed, that number of Neurons will be constructed for this Layer. |\r\n\r\n<a name=\"module_neural..Layer+isOutput\"></a>\r\n#### layer.isOutput() ⇒ <code>boolean</code>\r\nReturns whether this an output layer.  Note that all layers are output layers by default, until they have their neurons plugged into another layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n<a name=\"module_neural..Layer+setStatus\"></a>\r\n#### layer.setStatus(statuses)\r\nOverrides the layer's status.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| statuses | <code>Object</code> |  |\r\n| statuses.input | <code>boolean</code> | Whether the layer should be marked as an input layer. |\r\n| statuses.output | <code>boolean</code> | Whether the layer should be marked as an output layer. |\r\n\r\n<a name=\"module_neural..Layer+plug\"></a>\r\n#### layer.plug(outputLayer) ⇒ <code>Layer</code>\r\nPlugs this Layer into another Layer such that the Neurons in this Layer become input Neurons for the supplied Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Layer</code> - The supplied output Layer for chaining purposes.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| outputLayer | <code>Layer</code> | The Layer which will have its Neurons take the Neurons in this Layer as inputs. |\r\n\r\n<a name=\"module_neural..Layer+getNeurons\"></a>\r\n#### layer.getNeurons() ⇒ <code>Array</code>\r\nReturns the Neurons which make up this layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n<a name=\"module_neural..Layer+setInputs\"></a>\r\n#### layer.setInputs(inputs, isInputLayer)\r\nSets the inputs for all the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| inputs | <code>Array.&lt;(number\\|function()\\|Neuron)&gt;</code> | An array of inputs, which could be numbers, functions returning a number or Neurons. |\r\n| isInputLayer | <code>boolean</code> | Indicates whether this is intended to be the input layer in a Network.  If set to true, rather than each of the supplied inputs being wired into each of the Neurons in this Layer, they will be mapped one-to-one, with no bias (i.e. passed straight through to the next layer). |\r\n\r\n<a name=\"module_neural..Layer+setExpected\"></a>\r\n#### layer.setExpected(An)\r\nSets the expected values for the activation values of the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| An | <code>Array.&lt;number&gt;</code> | array of output values (numbers), equal in length to the number of Neurons in this Layer. |\r\n\r\n<a name=\"module_neural..Layer+setTransfer\"></a>\r\n#### layer.setTransfer(fn)\r\nSets the transfer function for every Neuron in this Layer\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| fn | <code>function</code> | The replacement transfer function (see section on transfer functions for details of acceptable formats). |\r\n\r\n<a name=\"module_neural..Layer+calc\"></a>\r\n#### layer.calc() ⇒ <code>Array</code>\r\nRecalculates the activation values for all of the Neurons in this Layer, recalculating their input Neuron values in sequence as required.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array</code> - The recalculated activation values.  \r\n<a name=\"module_neural..Layer+invalidate\"></a>\r\n#### layer.invalidate()\r\nInvalidates the activation cache for all the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n<a name=\"module_neural..Layer+calcDeltas\"></a>\r\n#### layer.calcDeltas() ⇒ <code>Array</code>\r\nRecalculates the deltas for all Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array</code> - The deltas for the Neurons in this Layer.  \r\n<a name=\"module_neural..Layer+getWeights\"></a>\r\n#### layer.getWeights() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nGets the weights for each Neuron in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - The weights for each Neuron in this Layer.  \r\n<a name=\"module_neural..Layer+setWeights\"></a>\r\n#### layer.setWeights(weights)\r\nUpdate the input weights for the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| weights | <code>Array.&lt;Array.&lt;number&gt;&gt;</code> | The new weights for each Neuron in this Layer. |\r\n\r\n<a name=\"module_neural..Layer+getActivations\"></a>\r\n#### layer.getActivations() ⇒ <code>Array</code>\r\nReturns the activation values for the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array</code> - The activation values.  \r\n<a name=\"module_neural..Layer+getInputSums\"></a>\r\n#### layer.getInputSums() ⇒ <code>Array</code>\r\nReturns the input sums for the Neurons in this Layer (the weighted sums of inputs for each Neuron before they've been passed through the transfer function).\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array</code> - The input sums.  \r\n<a name=\"module_neural..Layer+getIds\"></a>\r\n#### layer.getIds() ⇒ <code>Array</code>\r\nReturns the ids for the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array</code> - An array of ids.  \r\n<a name=\"module_neural..Layer+getOutputWeightPartials\"></a>\r\n#### layer.getOutputWeightPartials() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nReturns the output weight partials for the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - Array of output weight partials for each Neuron.  \r\n**See**: [Neuron#getOutputWeightPartials](Neuron#getOutputWeightPartials)  \r\n<a name=\"module_neural..Layer+getInputWeightPartials\"></a>\r\n#### layer.getInputWeightPartials() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nReturns the input weight partials for the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - Array of input weight partials for each Neuron.  \r\n**See**: [Neuron#getInputWeightPartials](Neuron#getInputWeightPartials)  \r\n<a name=\"module_neural..Layer+randomizeWeights\"></a>\r\n#### layer.randomizeWeights(e)\r\nRandomizes the weights for all of the Neurons in this Layer.\r\n\r\n**Kind**: instance method of <code>[Layer](#module_neural..Layer)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| e | <code>number</code> | The randomized weights will be in the range [-e, e]. |\r\n\r\n<a name=\"module_neural..Network\"></a>\r\n### neural~Network\r\n**Kind**: inner class of <code>[neural](#module_neural)</code>  \r\n\r\n* [~Network](#module_neural..Network)\r\n    * [new Network(params)](#new_module_neural..Network_new)\r\n    * [.layerCount()](#module_neural..Network+layerCount) ⇒ <code>number</code>\r\n    * [.getLayers()](#module_neural..Network+getLayers) ⇒ <code>Array</code>\r\n    * [.inputLayer()](#module_neural..Network+inputLayer) ⇒ <code>Layer</code>\r\n    * [.outputLayer()](#module_neural..Network+outputLayer) ⇒ <code>Layer</code>\r\n    * [.setInputs(inputs)](#module_neural..Network+setInputs)\r\n    * [.setExpected(outputs)](#module_neural..Network+setExpected)\r\n    * [.calc()](#module_neural..Network+calc) ⇒ <code>Array</code>\r\n    * [.getActivations()](#module_neural..Network+getActivations) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.getInputSums()](#module_neural..Network+getInputSums) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.invalidate()](#module_neural..Network+invalidate)\r\n    * [.randomizeWeights(e)](#module_neural..Network+randomizeWeights)\r\n    * [.forwardPropagate(trial)](#module_neural..Network+forwardPropagate) ⇒ <code>Array.&lt;number&gt;</code>\r\n    * [.sumSqError()](#module_neural..Network+sumSqError) ⇒ <code>number</code>\r\n    * [.backPropagate()](#module_neural..Network+backPropagate) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.getIds()](#module_neural..Network+getIds) ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\n    * [.getOutputWeightPartials()](#module_neural..Network+getOutputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n    * [.getInputWeightPartials()](#module_neural..Network+getInputWeightPartials) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n    * [.getWeights()](#module_neural..Network+getWeights) ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\n    * [.setWeights(The)](#module_neural..Network+setWeights)\r\n\r\n<a name=\"new_module_neural..Network_new\"></a>\r\n#### new Network(params)\r\nCreates a new Network\r\n\r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| params | <code>Object</code> |  |\r\n| [params.layers] | <code>Array.&lt;number&gt;</code> | An array of layer sizes, indicating the number of Neurons in each Layer (and implicitly, the number of Layers). |\r\n\r\n<a name=\"module_neural..Network+layerCount\"></a>\r\n#### network.layerCount() ⇒ <code>number</code>\r\nReturns the number of layers in the network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+getLayers\"></a>\r\n#### network.getLayers() ⇒ <code>Array</code>\r\nReturns the Layer instances which make up the network (from input to output).\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array</code> - Array of Layers.  \r\n<a name=\"module_neural..Network+inputLayer\"></a>\r\n#### network.inputLayer() ⇒ <code>Layer</code>\r\nReturns the Network's input Layer.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+outputLayer\"></a>\r\n#### network.outputLayer() ⇒ <code>Layer</code>\r\nReturns the Network's output Layer.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+setInputs\"></a>\r\n#### network.setInputs(inputs)\r\nSets the inputs for the Network's input Layer.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**See**: [Layer#setInputs](Layer#setInputs) for more details.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| inputs | <code>Array.&lt;(number\\|function()\\|Neuron)&gt;</code> | An array of inputs, which must be of the same length as the number of Neurons in the input Layer.  Note that whilst these could be Neurons, in an input Layer they would more normally be numbers or functions. |\r\n\r\n<a name=\"module_neural..Network+setExpected\"></a>\r\n#### network.setExpected(outputs)\r\nSets the expected outputs for the Network's output Layer.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**See**: [Layer#setOutputs](Layer#setOutputs) for more details.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| outputs | <code>Array.&lt;number&gt;</code> | An array of expected values for the output Layer.  This must be the same length as the number of Neurons in the output Layer. |\r\n\r\n<a name=\"module_neural..Network+calc\"></a>\r\n#### network.calc() ⇒ <code>Array</code>\r\nCalculates the output values for the Network based on the current inputs using forward propagation. Note that if Neuron activation values have been calculated since the previous invalidation, these will be used rather than recalculation occurring.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array</code> - The output layer activation values resulting from the current network inputs.  \r\n<a name=\"module_neural..Network+getActivations\"></a>\r\n#### network.getActivations() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nGets all activation values for all Neurons in all Layers in the Network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - Activation values.  \r\n<a name=\"module_neural..Network+getInputSums\"></a>\r\n#### network.getInputSums() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nGets all input sums for all Neurons in all Layers in the Network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - Input sums.  \r\n**See**: [Neuron#getInputSum](Neuron#getInputSum) for more details.  \r\n<a name=\"module_neural..Network+invalidate\"></a>\r\n#### network.invalidate()\r\nMarks the activation cache for every Neuron in the Network as invalid.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+randomizeWeights\"></a>\r\n#### network.randomizeWeights(e)\r\nRandomizes the input weights for all the Neurons in the Network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**See**: [Layer#randomizeWeights](Layer#randomizeWeights) for more details.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| e | <code>number</code> | Resulting weights will be in the interval [-e, e]. |\r\n\r\n<a name=\"module_neural..Network+forwardPropagate\"></a>\r\n#### network.forwardPropagate(trial) ⇒ <code>Array.&lt;number&gt;</code>\r\nPeforms a full forward propagation of the Network using the supplied input values.  Also optionally sets the expected output values for error calculation and training.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;number&gt;</code> - The actual output values resulting from the supplied inputs with the current network weights.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| trial | <code>Object</code> |  |\r\n| [trial.inputs] | <code>Array.&lt;number&gt;</code> | An array of input values to feed into the Network's input Layer.  This must be the same length as the number of Neurons in the input Layer. |\r\n| [trial.outputs=] | <code>Array.&lt;number&gt;</code> | An array of output values to mark as the output Layer's expected activation values.  This must be the same length as the number of Neurons in the output Layer. |\r\n\r\n<a name=\"module_neural..Network+sumSqError\"></a>\r\n#### network.sumSqError() ⇒ <code>number</code>\r\nReturns the sum-squared error resulting from comparing the calculated Network outputs with the expected outputs, using the current inputs and weights.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+backPropagate\"></a>\r\n#### network.backPropagate() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nApplies the back-propagation algorithm to recalculate the deltas for each Neuron in the Network, working from the output Layer to the input Layer.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;number&gt;&gt;</code> - The deltas for the Neurons in each of the output Layers.  \r\n<a name=\"module_neural..Network+getIds\"></a>\r\n#### network.getIds() ⇒ <code>Array.&lt;Array.&lt;number&gt;&gt;</code>\r\nReturns the ids for all the Neurons in the Network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n<a name=\"module_neural..Network+getOutputWeightPartials\"></a>\r\n#### network.getOutputWeightPartials() ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\nGets the output weight partials for each Neuron in the Network\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code> - Input weight partials for each Neuron.  \r\n**See**: [Neuron#getInputWeightPartials](Neuron#getInputWeightPartials)  \r\n<a name=\"module_neural..Network+getInputWeightPartials\"></a>\r\n#### network.getInputWeightPartials() ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\nGets the output weight partials for each Neuron in the Network\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code> - Output weight partials for each Neuron.  \r\n**See**: [Neuron#getOutputWeightPartials](Neuron#getOutputWeightPartials)  \r\n<a name=\"module_neural..Network+getWeights\"></a>\r\n#### network.getWeights() ⇒ <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code>\r\nGets the input weights for each Neuron in the network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n**Returns**: <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code> - Input weights by input, Neuron and Layer.  \r\n<a name=\"module_neural..Network+setWeights\"></a>\r\n#### network.setWeights(The)\r\nSets the weights for the entire network in one go.  Useful for rebuilding a trained network.\r\n\r\n**Kind**: instance method of <code>[Network](#module_neural..Network)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| The | <code>Array.&lt;Array.&lt;Array.&lt;number&gt;&gt;&gt;</code> | inner-most Arrays refer to the input weights for each Neuron.  These should be arranged in Arrays corresponding to each Neuron in a Layer.  Finally, the weights for each Layer should make up the outer-most Array. |\r\n\r\n<a name=\"module_neural..TrainingData\"></a>\r\n### neural~TrainingData\r\n**Kind**: inner class of <code>[neural](#module_neural)</code>  \r\n\r\n* [~TrainingData](#module_neural..TrainingData)\r\n    * [new TrainingData(data)](#new_module_neural..TrainingData_new)\r\n    * [.dataGenerator()](#module_neural..TrainingData+dataGenerator) ⇒ <code>generator</code>\r\n    * [.dataLength()](#module_neural..TrainingData+dataLength) ⇒ <code>number</code>\r\n\r\n<a name=\"new_module_neural..TrainingData_new\"></a>\r\n#### new TrainingData(data)\r\nCreates a new TrainingData object, which can be used to make generators which iterate over the supplied set of examples.  This is very useful for repeated training on a single set of data.\r\n\r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| data | <code>Array.&lt;object&gt;</code> | An array of trial objects pertaining to individual training examples. |\r\n| [trial.inputs] | <code>Array.&lt;number&gt;</code> | An array of inputs for this trial.  This must be the same length as the number of Neurons in the input layer of the Network that it will be used to train. |\r\n| [trial.outputs] | <code>Array.&lt;number&gt;</code> | An array of expected outputs for this trial.  This must be the same length as the number of Neurons in the output layer of the Network that it will be used to train. |\r\n\r\n<a name=\"module_neural..TrainingData+dataGenerator\"></a>\r\n#### trainingData.dataGenerator() ⇒ <code>generator</code>\r\nReturns a generator which iterators over the dataset which was used to construct the TrainingData object.\r\n\r\n**Kind**: instance method of <code>[TrainingData](#module_neural..TrainingData)</code>  \r\n<a name=\"module_neural..TrainingData+dataLength\"></a>\r\n#### trainingData.dataLength() ⇒ <code>number</code>\r\nGives the number of individual trials in the associated data set.\r\n\r\n**Kind**: instance method of <code>[TrainingData](#module_neural..TrainingData)</code>  \r\n<a name=\"module_neural..transferFunctions\"></a>\r\n### neural~transferFunctions : <code>object</code>\r\nThe store of transfer functions which can be used in Neurons to convert input sums to activation values.  By default, the following are available:\r\n\r\n**Kind**: inner namespace of <code>[neural](#module_neural)</code>  \r\n**Properties**\r\n\r\n| Name | Type | Description |\r\n| --- | --- | --- |\r\n| logSigmoid | <code>function</code> | see [https://en.wikipedia.org/wiki/Logistic_function](https://en.wikipedia.org/wiki/Logistic_function) |\r\n| rectifier | <code>function</code> | see [https://en.wikipedia.org/wiki/Rectifier_(neural_networks)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) |\r\n| linear | <code>function</code> | useful for output layers for training data which could take any value.  Note that neural networks cannot rely solely on linear transfer functions otherwise hidden layers will be effectively redundant. |\r\n\r\n<a name=\"module_neural..addTransferFunction\"></a>\r\n### neural~addTransferFunction(key, fn, deriv)\r\nAdds a function to the store of [transferFunctions](transferFunctions) which can be applied to Neurons to convert the input sum into an activation value.\r\n\r\n**Kind**: inner method of <code>[neural](#module_neural)</code>  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| key | <code>string</code> | transfer Function name |\r\n| fn | <code>one-to-one</code> | The transfer function itself, which should take a number and output a number.  It should be differentiable if it's to be used in network training. |\r\n| deriv | <code>one-to-one</code> | The derivative of the transfer function, which is required for back-propagation.  It should take a number and output a number. |\r\n\r\n<a name=\"module_neural..one-to-one\"></a>\r\n### neural~one-to-one ⇒ <code>number</code>\r\n**Kind**: inner typedef of <code>[neural](#module_neural)</code>  \r\n**Returns**: <code>number</code> - output Output value.  \r\n\r\n| Param | Type | Description |\r\n| --- | --- | --- |\r\n| input | <code>number</code> | Input value. |\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}