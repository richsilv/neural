<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: neural.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: neural.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>var matrix = require('./matrix')
var neuronId = 0
var transferFunctions = {}

/**
 * Creates a new Neuron
 * @constructor
 * @param {Object} params
 * @param {fn} [params.transfer='logSigmoid'] The neuron's transfer function.
 * @param {Array=} [params.inputs] An array of inputs to the neuron, which can be numbers, functions returning a number or Neurons
 * @param {Array=} [params.weights] The input weights with which to initialise the Neuron.  Defaults to zeros.
 */
function Neuron (params) {
  if (!(this instanceof Neuron)) return new Neuron(params)
  var transfer = params.transfer || transferFunctions.logSigmoid
  var inputs = params.inputs || []
  var weights = params.weights || matrix.zeros(inputs.length)
  var outputNeurons = []
  var expectedOutputVal = 0
  var activationCache = null
  var inputSumCache = null
  var delta = 0
  var id = (neuronId += 1)

  /**
   * Resets the inputs to a neuron.  Any existing inputs are removed.
   * @param  {Array} newInputs Array of inputs to the Neuron, which can be numbers, functions returning a number or Neurons.
   */
  this.setInputs = function (newInputs) {
    if (newInputs.length !== inputs.length) weights = matrix.zeros(newInputs.length)
    this.invalidate()
    inputs = newInputs
  }

  /**
   * Returns the Neurons inputs.
   * @return {Array}  The Neurons inputs, which could be numbers, functions returning a number or Neurons.
   */
  this.getInputs = function () {
    return inputs
  }

  /**
   * Returns the number of inputs feeding this neuron.
   * @return {number}  count of inputs, which could be numbers, functions returning a number of Neurons.
   */
  this.getInputCount = function () {
    return inputs.length
  }

  /**
   * Updates the Neuron's weights.
   * @param  {Array} newWeights An array of numbers, which must be of the same length as the Neuron's array of inputs.
   */
  this.updateWeights = function (newWeights) {
    this.invalidate()
    weights = newWeights.slice(0)
  }

  /**
   * Returns the Neuron's weights.
   * @return {Array}  The neuron's weights (numbers).
   */
  this.getWeights = function () {
    return weights.slice(0)
  }

  /**
   * Returns the Neuron's id.
   * @return {number}  The Neuron's id, which is unique at the module level.
   */
  this.getId = function () {
    return id
  }

  /**
   * Get the Neuron's transfer function
   * @return {fn}  The transfer function
   */
  this.getTransfer = function () {
    return transfer
  }

  /**
   * Sets the Neuron's transfer function
   * @param  {fn} The replacement transfer function (see section on transfer functions for details of acceptable formats).
   */
  this.setTransfer = function (fn) {
    transfer = fn
  }

  /**
   * Gets the Neuron's current activation value.  Note that this does NOT recalculate the value if input values or weights have changed.
   * @return {number}  The most recently-calculated activation value.
   */
  this.getActivation = function () {
    return activationCache
  }

  /**
   * Gets the Neuron's current input sum.  This is the weighted sum of inputs, prior to having been passed through the transfer function. Note that this does NOT recalculate the value if input values or weights have changed.
   * @return {number}  The most recently-calculated input sum.
   */
  this.getInputSum = function () {
    return inputSumCache
  }

  /**
   * Gets the Neuron's current delta.
   * @return {number}  The Neuron's delta.
   */
  this.getDelta = function () {
    return delta
  }

  /**
   * Indicates whether the Neuron is in the output layer of a Network
   * @return {boolean}
   */
  this.isOutput = function () {
    return expectedOutputVal !== null
  }

  /**
   * Sets the expected activation value (from training data) of the Neuron
   * @param  {number}  Expected output value
   */
  this.setExpected = function (val) {
    expectedOutputVal = val
  }

  this._updateOutputNeurons = function (neurons) {
    expectedOutputVal = null
    outputNeurons = neurons
  }

  /**
   * Plugs in a new input to the Neuron, which is initialised with a respective weight of 0.
   * @param  {number, fn or Neuron} The new input.
   */
  this.addInput = function (input) {
    inputs.push(input)
    weights.push(0)
    this.invalidate()
  }

  /**
   * Recalculates the activation value, recalculating all the input nodes in turn as required.
   * @return {number}  The recalculated activation value.
   */
  this.calc = function () {
    if (activationCache !== null) return activationCache
    inputSumCache = matrix.mult(matrix.invoke(inputs), matrix.transpose(weights), true)
    activationCache = transfer(inputSumCache)

    return activationCache
  }

  /**
   * The difference between the most recently calculated activation value and the last expected value to be supplied.
   * @return {number}  Difference between activation and expected values.
   */
  this.error = function () {
    return activationCache - expectedOutputVal
  }

  /**
   * Marks the Neuron as in need of recalculation by clearing the activation value cache.
   */
  this.invalidate = function () {
    activationCache = null
  }

  /**
   * Recalculates the Neuron's delta.
   * @return {number}  The new delta.
   */
  this.calcDelta = function () {
    if (this.isOutput()) return this._calcDeltaOutputLayer()
    delta = outputNeurons.reduce((total, neuron) => {
      var index = neuron.getInputs().findIndex(input => input.getId &amp;&amp; input.getId() === id)
      return total + (neuron.getDelta() * neuron.getWeights()[index])
    }, 0) * transfer.derivative(inputSumCache, activationCache)
    check(delta, 'Delta non-output layer')
    return delta
  }

  this._calcDeltaOutputLayer = function () {
    delta = -(expectedOutputVal - activationCache) * transfer.derivative(inputSumCache, activationCache)
    check.call(this, expectedOutputVal, 'expectedOutputVal')
    check.call(this, activationCache, 'activationCache')
    check.call(this, inputSumCache, 'inputSumCache')
    return delta
  }

  /**
   * Returns the partial derivative of the Neuron's error with respect to its output weights.
   * @return {Array}     The output weight partials.
   */
   this.getOutputWeightPartials = function () {
    return outputNeurons.map(neuron => activationCache * neuron.getDelta())
  }

  /**
   * Returns the partial derivatives of the input Neurons errors with respect to this Neuron's input weights.
   * @return {Array}  The input weight partials.
   */
  this.getInputWeightPartials = function () {
    return inputs.map(input => (input instanceof Neuron) ? input.getActivation() * delta : delta)
  }

  /**
   * Randomizes the Neuron's input weights.
   * @param  {number} [max=0.000001] Maximum possible weight.
   * @param  {number} [min=0] Minimum possible weights.
   */
  this.randomizeWeights = function (max, min) {
    return weights.map((weight, ind) => {
      var newWeight = randNum(max || 0.000001, min)
      weights[ind] = newWeight
    })
  }

  return this
}

/**
 * Creates a new Network Layer
 * @constructor
 * @param {Object} params
 * @param {number or Array} [params.neurons] The Neurons in the layer.  If an integer is passed, that number of Neurons will be constructed for this Layer.
 */

function Layer (params) {
  var neurons = []
  var isOutput = true
  var isInput = true

  if (!(this instanceof Layer)) return new Layer(params)
  if (params.neurons instanceof Array) {
    neurons = params.neurons
  }
  if (typeof params.neurons === 'number') {
    neurons = Array(params.neurons).fill(0).map(() => {
      return new Neuron(params)
    })
  }

  /**
   * Returns whether this an output layer.  Note that all layers are output layers by default, until they have their neurons plugged into another layer.
   * @return {boolean}
   */
  this.isOutput = function () {
    return isOutput
  }

  /**
   * Overrides the layer's status.
   * @param  {Object} statuses
   * @param  {boolean} statuses.input Whether the layer should be marked as an input layer.
   * @param  {boolean} statuses.output Whether the layer should be marked as an output layer.
   */
  this.setStatus = function (statuses) {
    if (typeof statuses.input === 'boolean') isInput = statuses.isInput
    if (typeof statuses.output === 'boolean') isOutput = statuses.isOutput
  }

  /**
   * Plugs this Layer into another Layer such that the Neurons in this Layer become input Neurons for the supplied Layer.
   * @param  {Layer} outputLayer The Layer which will have its Neurons take the Neurons in this Layer as inputs.
   * @return {Layer}             The supplied output Layer for chaining purposes.
   */
  this.plug = function (outputLayer) {
    // Add an extra input for bias
    outputLayer.setStatus({ input: false })
    outputLayer.setInputs(neurons.concat(1))
    isOutput = false
    neurons.forEach(neuron => {
      neuron._updateOutputNeurons(outputLayer.getNeurons())
    })
    return outputLayer
  }

  /**
   * Returns the Neurons which make up this layer.
   * @return {Array}
   */
  this.getNeurons = function () {
    return neurons
  }

  /**
   * Sets the inputs for all the Neurons in this Layer.
   * @param  {Array} inputs       An array of inputs, which could be numbers, functions returning a number or Neurons.
   * @param  {boolean} isInputLayer Indicates whether this is intended to be the input layer in a Network.  If set to true, rather than each of the supplied inputs being wired into each of the Neurons in this Layer, they will be mapped one-to-one, with no bias (i.e. passed straight through to the next layer).
   */
  this.setInputs = function (inputs, isInputLayer) {
    if (!(inputs instanceof Array)) throw new Error('Inputs must be an array')
    if (isInputLayer) {
      if (inputs.length !== neurons.length) throw new Error(`Number of inputs (${inputs.length}) differs from number of neurons in input layer (${neurons.length})`)
      isInput = true
      neurons.forEach((neuron, ind) => {
        neuron.setInputs([inputs[ind]])
        neuron.updateWeights([1])
      })
      this.getNeurons().forEach(neuron => neuron.setTransfer(transferFunctions.linear))
    } else {
      if (inputs.some(input => !(input instanceof Array))) {
        inputs = Array(neurons.length).fill(0).map(() => {
          return inputs.slice(0)
        })
      }
      inputs.forEach((inputArray, ind) => {
        neurons[ind].setInputs(inputArray)
      })
    }
  }

  /**
   * Sets the expected values for the activation values of the Neurons in this Layer.
   * @param  {Array} An array of output values (numbers), equal in length to the number of Neurons in this Layer.
   */
  this.setExpected = function (outputs) {
    if (!(outputs instanceof Array)) throw new Error('Outputs must be an array')
    if (outputs.length !== neurons.length) throw new Error(`Number of outputs (${outputs.length}) differs from number of neurons in layer (${neurons.length})`)
    neurons.forEach((neuron, ind) => neuron.setExpected(outputs[ind]))
  }

  /**
   * Sets the transfer function for every Neuron in this Layer
   * @param  {fn} fn The replacement transfer function (see section on transfer functions for details of acceptable formats).
   */
  this.setTransfer = function (fn) {
    return neurons.forEach(neuron => neuron.setTransfer(fn))
  }

  /**
   * Recalculates the activation values for all of the Neurons in this Layer, recalculating their input Neuron values in sequence as required.
   * @return {Array}  The recalculated activation values.
   */
  this.calc = function () {
    return neurons.map(neuron => neuron.calc())
  }

  /**
   * Invalidates the activation cache for all the Neurons in this Layer.
   */
  this.invalidate = function () {
    neurons.map(neuron => neuron.invalidate())
  }

  /**
   * Recalculates the deltas for all Neurons in this Layer.
   * @return {Array}  The deltas for the Neurons in this Layer.
   */
  this.calcDeltas = function () {
    return neurons.map(neuron => neuron.calcDelta())
  }

  /**
   * Gets the weights for each Neuron in this Layer.
   * @return {Array of Arrays}  The weights for each Neuron in this Layer.
   */
  this.getWeights = function () {
    return neurons.map(neuron => neuron.getWeights())
  }

  /**
   * Update the input weights for the Neurons in this Layer.
   * @param  {Array of Arrays} weights The new weights for each Neuron in this Layer.
   */
  this.setWeights = function (weights) {
    neurons.forEach((neuron, neuronInd) => neuron.updateWeights(weights[neuronInd]))
  }

  /**
   * Returns the activation values for the Neurons in this Layer.
   * @return {Array} The activation values.
   */
  this.getActivations = function () {
    return neurons.map(neuron => neuron.getActivation())
  }

  /**
   * Returns the input sums for the Neurons in this Layer (the weighted sums of inputs for each Neuron before they've been passed through the transfer function).
   * @return {Array} The input sums.
   */
  this.getInputSums = function () {
    return neurons.map(neuron => neuron.getInputSum())
  }

  /**
   * Returns the ids for the Neurons in this Layer.
   * @return {Array}  An array of ids.
   */
  this.getIds = function () {
    return neurons.map(neuron => neuron.getId())
  }

  /**
   * Returns the output weight partials for the Neurons in this Layer.
   * @see {@link Neuron#getOutputWeightPartials}
   * @return {Array of Arrays}  Array of output weight partials for each Neuron.
   */
  this.getOutputWeightPartials = function () {
    return neurons.map(neuron => neuron.getOutputWeightPartials())
  }

  /**
   * Returns the input weight partials for the Neurons in this Layer.
   * @see {@link Neuron#getInputWeightPartials}
   * @return {Array of Arrays}  Array of input weight partials for each Neuron.
   */
  this.getInputWeightPartials = function () {
    return neurons.map(neuron => neuron.getInputWeightPartials())
  }

  /**
   * Randomizes the weights for all of the Neurons in this Layer.
   * @param  {number} e The randomized weights will be in the range [-e, e].
   */
  this.randomizeWeights = function (e) {
    if (isInput) return
    neurons.forEach(neuron => neuron.randomizeWeights(-e, e))
  }

  return this
}

function Network (params) {
  if (!(this instanceof Network)) return new Network(params)
  var layers = []
  var alpha = (typeof params.alpha === 'number') ? params.alpha : 0.1
  var lambda = (typeof params.lambda === 'number') ? params.lambda : 0.1
  this.id = randomId()

  if (!(params.layers instanceof Array)) throw new Error('You must supply a "layers" parameter which is an array')
  params.layers.forEach(layer => {
    if (layer instanceof Layer) {
      layers.push(layer)
    } else if (typeof layer === 'number') {
      var layerParams = Object.assign({}, params, { neurons: layer })
      layers.push(new Layer(layerParams))
    } else {
      throw new Error('Unrecognised layer entry')
    }
  })

  layers.reduce((lastLayer, thisLayer) => {
    if (lastLayer) lastLayer.plug(thisLayer)
    return thisLayer
  }, null)

  this.layerCount = function () {
    return layers.length
  }

  this.getLayers = function () {
    return layers
  }

  this.inputLayer = function () {
    return layers[0]
  }

  this.outputLayer = function () {
    return layers[layers.length - 1]
  }

  this.setInputs = function (inputs) {
    return this.inputLayer().setInputs(inputs, true)
  }

  this.setExpected = function (outputs) {
    return this.outputLayer().setExpected(outputs)
  }

  this.getAlpha = function () {
    return alpha
  }

  this.setAlpha = function (newAlpha) {
    return alpha = newAlpha
  }

  this.calc = function (trialInputs) {
    if (trialInputs) {
      this.invalidate()
      this.setInputs(trialInputs)
    }
    return this.outputLayer().calc()
  }

  this.getActivations = function () {
    return layers.map(layer => layer.getActivations())
  }

  this.getInputSums = function () {
    return layers.map(layer => layer.getInputSums())
  }

  this.invalidate = function () {
    return layers.map(layer => layer.invalidate())
  }

  this.randomizeWeights = function (e) {
    layers.forEach(layer => layer.randomizeWeights(e))
  }

  this.forwardPropagate = function (iter) {
    this.invalidate()
    this.setInputs(iter.inputs)
    this.setExpected(iter.outputs)
    return this.calc()
  }

  this.sumSqError = function () {
    return 0.5 * this.outputLayer().getNeurons().reduce((sum, neuron) => {
      return sum + Math.pow(neuron.error(), 2)
    }, 0)
  }

  this.backPropagate = function () {
    this.invalidate()
    this.calc()
    var layerCount = this.layerCount()
    return layers.map((ignore, ind) => {
      var layer = layers[layerCount - ind - 1]
      return layer.calcDeltas()
    })
  }

  this.getIds = function () {
    return layers.map(layer => layer.getIds())
  }
  this.getOutputWeightPartials = function () {
    return layers.map(layer => layer.getOutputWeightPartials())
  }
  this.getInputWeightPartials = function () {
    return layers.map(layer => layer.getInputWeightPartials())
  }
  this.getWeights = function () {
    return layers.map(layer => layer.getWeights())
  }
  this.setWeights = function (weights) {
    layers.map((layer, layerInd) => layer.setWeights(weights[layerInd].slice(0)))
  }

  console.log(`Made neural network, alpha = ${alpha}, lambda = ${lambda}`)
  return this
}

function TrainingData (data) {
  if (!(this instanceof TrainingData)) return new TrainingData(data)
  var dataLength = data.length

  function *dataGen () {
    yield* data
    return dataLength
  }

  this.dataGenerator = function () {
    return dataGen()
  }

  this.dataLength = function () {
    return dataLength
  }

  return this
}

function* trainer (network, trainingData, opts) {
  opts = opts || {}
  var alpha = opts.alpha || network.alpha || 0.5
  var alphaUpdater = alphaUpdaterGen(alpha)
  var lambda = opts.lamdba || network.lambda || 0.01
  var dataLength = trainingData.dataLength()
  var progressiveAlpha = opts.progressiveAlpha ? {
    creep: opts.progressiveAlpha.creep,
    reversal: opts.progressiveAlpha.reversal,
    floor: opts.progressiveAlpha.floor
  } : false
  var verbose = opts.verbose
  var minError
  var bestWeights
  var epoch = 0
  var complete = false

  network.randomizeWeights(0.00000001)
  while (!complete) {
    complete = yield runEpoch()
  }

  function runEpoch () {
    epoch += 1
    var dataGen = trainingData.dataGenerator()
    var error = 0
    var outputs = []

    for (var trial of dataGen) {
      error += feedForwardAndCalcError(trial)
      network.backPropagate()
      if (verbose) {
        outputs.push(network.outputLayer().getActivations())
      }
      updateNetworkWeights(network.getInputWeightPartials())
    }

    var weightedError = Math.pow(error / dataLength, 0.5)
    if (progressiveAlpha) alpha = alphaUpdater.next(weightedError).value
    if (!minError || weightedError &lt; minError) {
      minError = weightedError
      bestWeights = network.getWeights()
    }
    var result = {
      epoch: epoch,
      error: weightedError,
      minError: minError,
      bestWeights: bestWeights,
      alpha: alpha
    }
    if (verbose) result.outputs = outputs
    return result
  }

  function feedForwardAndCalcError (trial) {
    network.forwardPropagate(trial)
    return network.sumSqError()
  }

  function updateNetworkWeights (weightMap) {
    var layers = network.getLayers()
    layers.forEach((layer, layerInd) => {
      if (layerInd === 0) return
      layer.getNeurons().forEach((neuron, neuronInd) => {
        var neuronWeights = neuron.getWeights()
        var weightMapThisNeuron = weightMap[layerInd][neuronInd]
        neuronWeights = neuronWeights.map((neuronWeight, neuronWeightInd) => {
          return neuronWeight - (alpha * (weightMapThisNeuron[neuronWeightInd] + (lambda * neuronWeight / dataLength)))
        })
        neuron.updateWeights(neuronWeights)
      })
    })
  }

  function* alphaUpdaterGen (alpha) {
    alpha = alpha || 0.5
    var error
    var lastError
    while (true)  {
      if (error &amp;&amp; lastError) {
        if (error &lt;= lastError) alpha *= progressiveAlpha.creep
        else alpha *= progressiveAlpha.reversal
      }
      if (progressiveAlpha.floor &amp;&amp; alpha &lt; progressiveAlpha.floor) alpha = progressiveAlpha.floor
      lastError = error
      error = yield alpha
    }
  }
}

function batch (trainer, freq) {
  var timer = new Date()
  var next = function (inp) {
    return new Promise(resolve => {
      var newTime = new Date()
      if ((newTime - timer) > freq) {
        setTimeout(() => {
          timer = newTime
          resolve(trainer.next(inp))
        }, 0)
      } else {
        resolve(trainer.next(inp))
      }
    })
  }

  return { next }
}

function race (trainerArrayInput, rules, opts) {
  opts = opts || {}
  var epoch = 0
  var trainerArray = trainerArrayInput.slice(0)
  var lastResults = []
  var errorThreshold = opts.errorThreshold || 0
  var maxEpochs = opts.maxEpochs || null
  var currMinError
  while ((!currMinError || currMinError > errorThreshold) &amp;&amp; (!maxEpochs || epoch &lt;= maxEpochs)) {
    lastResults = trainerArray.map((trainer, ind) => {
      return (lastResults[ind] &amp;&amp; lastResults[ind].done) ? lastResults[ind] : trainer.gen.next()
    })
    currMinError = calcCurrMinError(lastResults)
    if (rules[epoch]) {
      console.log(`Trimming to ${rules[epoch]} trainers`)
      trainerArray = trim(trainerArray, lastResults, rules[epoch])
    }
    console.log(`Epoch ${epoch} - current global min error is ${currMinError}`)
    epoch = epoch + 1
  }

  return trainerArray

  function trim (trainerArray, lastResults, num) {
    var indices = lastResults.slice(0).sort(results => -results.value.minError).map(results => lastResults.findIndex(theseResults => results.value.error === theseResults.value.error)).slice(0, num)
    return indices.map(ind => trainerArray[ind])
  }

  function calcCurrMinError (lastResults) {
    return lastResults.reduce((min, results) => (min === null || results.value.error &lt; min) ? results.value.error : min, null)
  }
}

function randNum (max, min) {
  max = max || 1
  min = min || 0
  return (Math.random() * (max - min)) + min
}

function addTransferFunction (key, fn, deriv) {
  transferFunctions[key] = fn
  transferFunctions[key].derivative = deriv
}

addTransferFunction('logSigmoid', function logSigmoid (x) {
  return (1 / (1 + Math.exp(-x)))
}, function logSigmoidDeriv (inputSum, activation) {
  return activation * (1 - activation)
})

addTransferFunction('linear', function linear (x) {
  return x
}, function linearDeriv () {
  return 1
})

addTransferFunction('rectifier', function rectifier (x) {
  return Math.log(1 + Math.exp(x))
}, function rectifierDeriv (inputSum) {
  return (1 / (1 + Math.exp(-inputSum)))
})

function randomId () {
  return 'xxxxxxxxxxxx'.replace(/[x]/g, () => {
    var r = Math.random()*16|0
    return r.toString(16)
  })
}

function networkSum(X, Y, ignoreLayers) {
  return X.map((xLayer, layerInd) => {
    if (ignoreLayers &amp;&amp; ignoreLayers.some(ind => ind === layerInd)) return xLayer
    return xLayer.map((xNeuron, neuronInd) => {
      return xNeuron.map((xWeight, weightInd) => {
        return xWeight + Y[layerInd][neuronInd][weightInd]
      })
    })
  })
}

function check (value, message) {
  if (isNaN(value)) {
    throw new Error(`Overflow: ${message}`)
  }
}

module.exports = {
  Neuron,
  Layer,
  Network,
  TrainingData,
  trainer,
  batch,
  race,
  transferFunctions
}
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Layer.html">Layer</a></li><li><a href="Neuron.html">Neuron</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.4.0</a> on Fri Feb 05 2016 16:19:49 GMT+0000 (GMT)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
